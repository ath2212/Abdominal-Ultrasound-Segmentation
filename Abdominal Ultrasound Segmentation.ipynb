{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-03T15:26:13.524435Z","iopub.execute_input":"2021-12-03T15:26:13.524772Z","iopub.status.idle":"2021-12-03T15:26:14.488904Z","shell.execute_reply.started":"2021-12-03T15:26:13.524687Z","shell.execute_reply":"2021-12-03T15:26:14.488206Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from PIL import Image, ImageOps\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2 as cv \n\ntrain_image_names = []\ntrain_mask_names = []\n\nfor root, _, files in os.walk('../input/ussimandsegm/abdominal_US/abdominal_US/AUS/images/train'):\n    for i in files:\n        img_path = os.path.join('../input/ussimandsegm/abdominal_US/abdominal_US/AUS/images/train', i)\n        mask_path = os.path.join('../input/ussimandsegm/abdominal_US/abdominal_US/AUS/annotations/train', i)\n        train_image_names.append(img_path)\n        train_mask_names.append(mask_path)\n\nfor root, _, files in os.walk('../input/ussimandsegm/abdominal_US/abdominal_US/AUS/images/test'):\n    for i in files:\n        img_path = os.path.join('../input/ussimandsegm/abdominal_US/abdominal_US/AUS/images/test', i)\n        mask_path = os.path.join('../input/ussimandsegm/abdominal_US/abdominal_US/AUS/annotations/test', i)\n        train_image_names.append(img_path)\n        train_mask_names.append(mask_path)\n\nn=13\nfig, axs = plt.subplots(1,2, figsize=[13,15])\nimage = cv.imread(train_image_names[n], 0)\n#image = ImageOps.grayscale(image)\n#image = np.array(image)\nmask = cv.imread(train_mask_names[n])\n#mask = ImageOps.grayscale(mask)\n#mask = np.array(mask)\nmask = np.where(mask==(10), (0), mask)\nmask = cv.cvtColor(mask, cv.COLOR_BGR2GRAY)\naxs[0].imshow(image)\naxs[1].imshow(mask)\nprint(len(train_mask_names), len(train_image_names))\nprint(mask[0].shape)\nprint(np.unique(mask))","metadata":{"execution":{"iopub.status.busy":"2021-12-03T15:26:14.490209Z","iopub.execute_input":"2021-12-03T15:26:14.490412Z","iopub.status.idle":"2021-12-03T15:26:15.251911Z","shell.execute_reply.started":"2021-12-03T15:26:14.490388Z","shell.execute_reply":"2021-12-03T15:26:15.251240Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\nimages = []\nmasks = []\nimg_height = 256\nimg_width = 256\n\nfor i in train_image_names:\n    image = cv.imread(i)\n    image = cv.resize(image, (img_height, img_width), interpolation = cv.INTER_AREA)\n    image = image/255.0\n    images.append(image)\n\nfor i in train_mask_names:\n    mask = cv.imread(i)\n    mask = np.where(mask==(10), (0), mask)\n    mask = cv.cvtColor(mask, cv.COLOR_BGR2GRAY)\n    mask = cv.resize(mask, (img_height, img_width), interpolation=cv.INTER_NEAREST)\n    if 2 in np.unique(mask):\n        print(\"Error\") #sanity\n    masks.append(mask)\n\nimages = np.array(images)\nimages = np.expand_dims(images, axis=3)\nimages = np.reshape(images, (-1, 256, 256, 3))\nmasks = np.array(masks)","metadata":{"execution":{"iopub.status.busy":"2021-12-03T15:26:15.253113Z","iopub.execute_input":"2021-12-03T15:26:15.253470Z","iopub.status.idle":"2021-12-03T15:26:39.716814Z","shell.execute_reply.started":"2021-12-03T15:26:15.253438Z","shell.execute_reply":"2021-12-03T15:26:39.716062Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"print(np.unique(masks))\nprint(images.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-03T15:26:39.718664Z","iopub.execute_input":"2021-12-03T15:26:39.718938Z","iopub.status.idle":"2021-12-03T15:26:40.798661Z","shell.execute_reply.started":"2021-12-03T15:26:39.718905Z","shell.execute_reply":"2021-12-03T15:26:40.797240Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\nprint(tf.__version__)\n\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPool2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, Dropout, BatchNormalization, Activation, Lambda\nfrom tensorflow.keras.layers import Cropping2D, Add\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam","metadata":{"execution":{"iopub.status.busy":"2021-12-03T15:26:40.805420Z","iopub.execute_input":"2021-12-03T15:26:40.805948Z","iopub.status.idle":"2021-12-03T15:26:45.480305Z","shell.execute_reply.started":"2021-12-03T15:26:40.805903Z","shell.execute_reply":"2021-12-03T15:26:45.479584Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def unet_model(no_classes, img_height, img_width):\n    input = Input((img_height, img_width, 3), name='images')\n    s = input\n\n    c1 = Conv2D(16, (3,3), activation='relu', kernel_initializer = 'he_normal',padding='same')(s)\n    c1 = BatchNormalization()(c1)\n    c1 = Dropout(0.1)(c1)\n    c1 = Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n    c1 = BatchNormalization()(c1)\n    p1 = MaxPool2D((2,2))(c1)\n\n    c2 = Conv2D(32, (3,3), activation='relu', kernel_initializer = 'he_normal',padding='same')(p1)\n    c2 = BatchNormalization()(c2)\n    c2 = Dropout(0.1)(c2)\n    c2 = Conv2D(32, (3,3), activation='relu', kernel_initializer = 'he_normal',padding='same')(c2)\n    c2 = BatchNormalization()(c2)\n    p2 = MaxPool2D((2,2))(c2)\n\n    c3 = Conv2D(64, (3,3), activation='relu', kernel_initializer = 'he_normal',padding='same')(p2)\n    c3 = BatchNormalization()(c3)\n    c3 = Dropout(0.1)(c3)\n    c3 = Conv2D(64, (3,3), activation='relu', kernel_initializer = 'he_normal',padding='same')(c3)\n    c3 = BatchNormalization()(c3)\n    p3 = MaxPool2D((2,2))(c3)    \n\n    c4 = Conv2D(128, (3,3), activation='relu', kernel_initializer = 'he_normal',padding='same')(p3)\n    c4 = BatchNormalization()(c4)\n    c4 = Dropout(0.1)(c4)\n    c4 = Conv2D(128, (3,3), activation='relu', kernel_initializer = 'he_normal',padding='same')(c4)\n    c4 = BatchNormalization()(c4)\n    p4 = MaxPool2D((2,2))(c4)\n\n    c5 = Conv2D(256, (3,3), activation='relu', kernel_initializer = 'he_normal',padding='same')(p4)\n    c5 = BatchNormalization()(c5)\n    c5 = Dropout(0.1)(c5)\n    c5 = Conv2D(256, (3,3), activation='relu', kernel_initializer = 'he_normal',padding='same')(c5)\n    c5 = BatchNormalization()(c5)\n    p5 = MaxPool2D((2,2))(c5)\n\n    c6 = Conv2D(512, (3,3), activation='relu', kernel_initializer = 'he_normal',padding='same')(p5)\n    c6 = BatchNormalization()(c6)\n    c6 = Dropout(0.1)(c6)\n    c6 = Conv2D(512, (3,3), activation='relu', kernel_initializer = 'he_normal',padding='same')(c6)\n    c6 = BatchNormalization()(c6)\n\n    u7 = Conv2DTranspose(256, (2,2), strides=(2,2), padding='same')(c6)\n    u7 = concatenate([u7, c5])\n    c7 = Conv2D(256, (3,3), activation='relu', kernel_initializer = 'he_normal',padding='same')(u7)\n    c7 = BatchNormalization()(c7)\n    c7 = Dropout(0.1)(c7)\n    c7 = Conv2D(256, (3,3), activation='relu', kernel_initializer = 'he_normal',padding='same')(c7)\n    c7 = BatchNormalization()(c7)\n\n    u8 = Conv2DTranspose(128, (2,2), strides=(2,2), padding='same')(c7)\n    u8 = concatenate([u8, c4])\n    c8 = Conv2D(128, (3,3), activation='relu', kernel_initializer = 'he_normal',padding='same')(u8)\n    c8 = BatchNormalization()(c8)\n    c8 = Dropout(0.1)(c8)\n    c8 = Conv2D(128, (3,3), activation='relu', kernel_initializer = 'he_normal',padding='same')(c8)\n    c8 = BatchNormalization()(c8)\n\n    u9 = Conv2DTranspose(64, (2,2), strides=(2,2), padding='same')(c8)\n    u9 = concatenate([u9, c3])\n    c9 = Conv2D(64, (3,3), activation='relu', kernel_initializer = 'he_normal',padding='same')(u9)\n    c9 = BatchNormalization()(c9)\n    c9 = Dropout(0.1)(c9)\n    c9 = Conv2D(64, (3,3), activation='relu', kernel_initializer = 'he_normal',padding='same')(c9)\n    c9 = BatchNormalization()(c9)\n\n    u10 = Conv2DTranspose(32, (2,2), strides=(2,2), padding='same')(c9)\n    u10 = concatenate([u10, c2])\n    c10 = Conv2D(32, (3,3), activation='relu', kernel_initializer = 'he_normal',padding='same')(u10)\n    c10 = BatchNormalization()(c10)\n    c10 = Dropout(0.1)(c10)\n    c10 = Conv2D(32, (3,3), activation='relu', kernel_initializer = 'he_normal',padding='same')(c10)\n    c10 = BatchNormalization()(c10)\n\n    u11 = Conv2DTranspose(16, (2,2), strides=(2,2), padding='same')(c10)\n    u11 = concatenate([u11, c1])\n    c11 = Conv2D(16, (3,3), activation='relu', kernel_initializer = 'he_normal',padding='same')(u11)\n    c11 = BatchNormalization()(c11)\n    c11 = Dropout(0.1)(c11)\n    c11 = Conv2D(16, (3,3), activation='relu', kernel_initializer = 'he_normal',padding='same')(c11)\n    c11 = BatchNormalization()(c11)\n\n    output = Conv2D(no_classes, (1,1), activation=\"softmax\", name='masks')(c11)\n\n    model = Model(inputs=[input], outputs=[output])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-03T15:26:45.481790Z","iopub.execute_input":"2021-12-03T15:26:45.482038Z","iopub.status.idle":"2021-12-03T15:26:45.511593Z","shell.execute_reply.started":"2021-12-03T15:26:45.482005Z","shell.execute_reply":"2021-12-03T15:26:45.510936Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_images, test_images, train_masks, test_masks = train_test_split(images, masks, test_size=0.1)","metadata":{"execution":{"iopub.status.busy":"2021-12-03T15:26:45.513030Z","iopub.execute_input":"2021-12-03T15:26:45.513685Z","iopub.status.idle":"2021-12-03T15:26:46.394296Z","shell.execute_reply.started":"2021-12-03T15:26:45.513649Z","shell.execute_reply":"2021-12-03T15:26:46.393573Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"plt.imshow(test_images[0])","metadata":{"execution":{"iopub.status.busy":"2021-12-03T15:26:46.395738Z","iopub.execute_input":"2021-12-03T15:26:46.395981Z","iopub.status.idle":"2021-12-03T15:26:46.602384Z","shell.execute_reply.started":"2021-12-03T15:26:46.395948Z","shell.execute_reply":"2021-12-03T15:26:46.601706Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"print(train_images.shape, train_masks.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-03T15:26:56.880821Z","iopub.execute_input":"2021-12-03T15:26:56.881075Z","iopub.status.idle":"2021-12-03T15:26:56.885914Z","shell.execute_reply.started":"2021-12-03T15:26:56.881045Z","shell.execute_reply":"2021-12-03T15:26:56.885178Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\nfrom sklearn.preprocessing import LabelEncoder\n\ndef data_generator(images, masks, batch_size=8):\n    while True:\n        i=0\n        while i<len(images)//batch_size:\n            image_batch=np.zeros((batch_size, img_height, img_width, 3))\n            mask_batch=np.zeros((batch_size, img_height, img_width))\n\n            for j in range(batch_size):\n                image, mask = images[i*j+j], masks[i*j+j]\n                image_batch[j] = image\n                mask_batch[j] = mask\n                labelencoder = LabelEncoder()\n                n, h, w = mask_batch.shape\n                mask_batch_reshaped = mask_batch.reshape(-1, 1)\n                mask_batch_reshaped_encoded = labelencoder.fit_transform(mask_batch_reshaped)\n                mask_batch_encoded = mask_batch_reshaped_encoded.reshape(n, h, w)\n                mask_batch_encoded = np.expand_dims(mask_batch_encoded, axis=3)\n                mask_batch_cat = to_categorical(mask_batch_encoded, num_classes=9)\n            i+=1\n            yield {'images':image_batch}, {'masks':mask_batch_cat}","metadata":{"execution":{"iopub.status.busy":"2021-12-03T16:55:33.778041Z","iopub.execute_input":"2021-12-03T16:55:33.778299Z","iopub.status.idle":"2021-12-03T16:55:33.786822Z","shell.execute_reply.started":"2021-12-03T16:55:33.778267Z","shell.execute_reply":"2021-12-03T16:55:33.786062Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"n, h, w = test_masks.shape\nlabelencoder = LabelEncoder()\ntest_masks_reshaped = test_masks.reshape(-1, 1)\ntest_masks_reshaped_encoded = labelencoder.fit_transform(test_masks_reshaped)\ntest_masks_encoded = test_masks_reshaped_encoded.reshape(n, h, w)\ntest_masks_encoded = np.expand_dims(test_masks_encoded, axis=3)\n\nnp.unique(test_masks_encoded)","metadata":{"execution":{"iopub.status.busy":"2021-12-03T15:26:57.729105Z","iopub.execute_input":"2021-12-03T15:26:57.729613Z","iopub.status.idle":"2021-12-03T15:26:58.018884Z","shell.execute_reply.started":"2021-12-03T15:26:57.729574Z","shell.execute_reply":"2021-12-03T15:26:58.018030Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def get_model():\n    return unet_model(no_classes=9, img_height=img_height, img_width=img_width)","metadata":{"execution":{"iopub.status.busy":"2021-12-03T15:26:58.050977Z","iopub.execute_input":"2021-12-03T15:26:58.051177Z","iopub.status.idle":"2021-12-03T15:26:58.055263Z","shell.execute_reply.started":"2021-12-03T15:26:58.051153Z","shell.execute_reply":"2021-12-03T15:26:58.054636Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def jaccard_loss(y_true, y_pred, smooth=1):\n    \"\"\"\n    Arguments:\n        y_true : Matrix containing one-hot encoded class labels \n                 with the last axis being the number of classes.\n        y_pred : Matrix with same dimensions as y_true.\n        smooth : smoothing factor for loss function.\n    \"\"\"\n\n    intersection = tf.reduce_sum( y_true * y_pred, axis=-1)\n    union = tf.reduce_sum(y_true + y_pred, axis=-1) - intersection\n    jac = (intersection + smooth) / (union + smooth)\n    \n    return (1 - jac) * smooth","metadata":{"execution":{"iopub.status.busy":"2021-12-03T15:26:58.382600Z","iopub.execute_input":"2021-12-03T15:26:58.383496Z","iopub.status.idle":"2021-12-03T15:26:58.390341Z","shell.execute_reply.started":"2021-12-03T15:26:58.383450Z","shell.execute_reply":"2021-12-03T15:26:58.389619Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model=get_model()\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[jaccard_loss])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-03T15:26:58.847860Z","iopub.execute_input":"2021-12-03T15:26:58.848501Z","iopub.status.idle":"2021-12-03T15:27:01.491346Z","shell.execute_reply.started":"2021-12-03T15:26:58.848463Z","shell.execute_reply":"2021-12-03T15:27:01.490598Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"history = model.fit(data_generator(train_images, train_masks, 8),\n                    steps_per_epoch = len(train_images)//8,\n                    validation_data=data_generator(test_images, test_masks, 8),\n                    validation_steps = len(test_images)//8,\n                    epochs=50)#200 zhalele","metadata":{"execution":{"iopub.status.busy":"2021-12-03T16:56:34.644052Z","iopub.execute_input":"2021-12-03T16:56:34.644302Z","iopub.status.idle":"2021-12-03T17:15:56.793635Z","shell.execute_reply.started":"2021-12-03T16:56:34.644273Z","shell.execute_reply":"2021-12-03T17:15:56.792777Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"n=5\nfig, axs = plt.subplots(1,3, figsize=[13,15])\nimage = test_images[n]\nimage = cv.resize(image, (256,256), interpolation=cv.INTER_AREA)\n#image = image/255.0\nimage_input = np.expand_dims(image, axis=0)\nmask = test_masks[n]\n'''mask = np.where(mask==(10), (0), mask)\nmask = cv.cvtColor(mask, cv.COLOR_BGR2GRAY)\nmask = cv.resize(mask, (256, 256), interpolation = cv.INTER_NEAREST)'''\nprediction = model.predict(image_input)\n#print(prediction.shape)\nprediction_img = np.argmax(prediction[:,:,:,0:], axis=3)[0]\naxs[0].imshow(image)\naxs[1].imshow(mask, cmap='jet')\naxs[2].imshow(prediction_img, cmap='jet')\n#print(prediction_img)","metadata":{"execution":{"iopub.status.busy":"2021-12-03T17:18:24.824317Z","iopub.execute_input":"2021-12-03T17:18:24.824868Z","iopub.status.idle":"2021-12-03T17:18:25.548002Z","shell.execute_reply.started":"2021-12-03T17:18:24.824828Z","shell.execute_reply":"2021-12-03T17:18:25.547388Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}